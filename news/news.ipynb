{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import collections\n",
    "import math\n",
    "import numpy as np\n",
    "import operator\n",
    "import random\n",
    "import math\n",
    "from math import log\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = []\n",
    "with open('stop_words.txt', encoding='utf-8') as inp:\n",
    "    m = inp.readlines()\n",
    "    n = m[0].split(',')\n",
    "    stop_words.append(n)\n",
    "stop_words = stop_words[0]\n",
    "len(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spread(arg):\n",
    "    ret = []\n",
    "    for i in arg:\n",
    "        if isinstance(i, list):\n",
    "            ret.extend(i)\n",
    "        else:\n",
    "            ret.append(i)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_flatten(arr):\n",
    "    result = []\n",
    "    result.extend(\n",
    "        spread(list(map(lambda x: deep_flatten(x) if type(x) == list else x, arr)))\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    min_length = 3\n",
    "    text = text.lower()\n",
    "    pattern = re.compile('[a-zа-я]+')\n",
    "    result = pattern.findall(text)\n",
    "    stemmer_ru = SnowballStemmer('russian')\n",
    "    stemmer_en = SnowballStemmer('english')\n",
    "    tokens = [stemmer_ru.stem(stemmer_en.stem(word)) for word in result]\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    filtered_tokens = list(\n",
    "        filter(lambda token: len(token) >= min_length, tokens)\n",
    "    )\n",
    "    return filtered_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dict(t):\n",
    "    dic = collections.Counter()\n",
    "    for i in t:\n",
    "        dic += collections.Counter(i)\n",
    "    return dict(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 3)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('data/news_train.csv', sep='\\t')\n",
    "print(train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "theme = np.unique(train['theme'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['business' 'culture' 'economics' 'forces' 'life' 'media' 'science'\n",
      " 'sport' 'style' 'travel']\n"
     ]
    }
   ],
   "source": [
    "print(theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = ['business'] * 2099\n",
    "Y.append(['culture'] * 8405)\n",
    "Y.append(['economics'] * 8545)\n",
    "Y.append(['forces'] * 4758)\n",
    "Y.append(['life'] * 8083)\n",
    "Y.append(['media'] * 8629)\n",
    "Y.append(['science'] * 8657)\n",
    "Y.append(['sport'] * 8510)\n",
    "Y.append(['style'] * 1148)\n",
    "Y.append(['travel'] * 1166)\n",
    "Y = deep_flatten(Y)\n",
    "Y = pd.DataFrame({'theme': Y})\n",
    "Y.to_csv('Y.csv', sep=',', encoding='utf-8', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализация Train и выделение 1000 самых встречающихся слов в каждой теме"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2099, 3)\n",
      "2099\n",
      "(8405, 3)\n",
      "10504\n",
      "(8545, 3)\n",
      "19049\n",
      "(4758, 3)\n",
      "23807\n",
      "(8083, 3)\n",
      "31890\n",
      "(8629, 3)\n",
      "40519\n",
      "(8657, 3)\n",
      "49176\n",
      "(8510, 3)\n",
      "57686\n",
      "(1148, 3)\n",
      "58834\n",
      "(1166, 3)\n",
      "60000\n"
     ]
    }
   ],
   "source": [
    "Train = []\n",
    "for k in theme:\n",
    "    th = train[train['theme'] == k]\n",
    "    print(th.shape)\n",
    "    text = th['text'].apply(lambda x: tokenize(x))\n",
    "    text = list(text)\n",
    "    dic = make_dict(text)\n",
    "    newDic = []\n",
    "    sorted_dic = dict(sorted(dic.items(), key=operator.itemgetter(1))[::-1])\n",
    "    newDic = list(sorted_dic.keys())[:1000]\n",
    "    t = []\n",
    "    for i in text:\n",
    "        for j in i:\n",
    "            if j in newDic:\n",
    "                t.append(j)\n",
    "        Train.append(t)\n",
    "        t = []\n",
    "    print(len(Train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.read_csv('Y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.replace(['business', 'culture', 'economics', 'forces', 'life', 'media', 'science', 'sport', 'style','travel'],\n",
    "          [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train, Y = shuffle(Train, Y, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('newTrain.txt', 'w', encoding='utf-8') as out:\n",
    "    for i in Train:\n",
    "        for j in i:\n",
    "            out.write('{},'.format(j))\n",
    "        out.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.to_csv('Y.csv', sep=',', encoding='utf-8', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализация Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/news_test.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test['text'].apply(lambda x: tokenize(x))\n",
    "with open('newTest.txt', 'w', encoding='utf-8') as out:\n",
    "    for i in list(test):\n",
    "        for j in i:\n",
    "            out.write('{},'.format(j))\n",
    "        out.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представление текста в виде count матрицы "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = []\n",
    "with open('newTrain.txt', encoding='utf-8') as inp:\n",
    "    for i in inp.readlines():\n",
    "        nn = i.split(',')\n",
    "        nn.remove('\\n')\n",
    "        Train.append(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = []\n",
    "with open('newTest.txt', encoding='utf-8') as inp:\n",
    "    for i in inp.readlines():\n",
    "        nn = i.split(',')\n",
    "        nn.remove('\\n')\n",
    "        Test.append(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.read_csv('Y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conuntVec(doc, dic):\n",
    "    c = []\n",
    "    for i in dic:\n",
    "        c.append(doc.count(i))\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = Train.copy()\n",
    "text.extend(Test)\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3520\n"
     ]
    }
   ],
   "source": [
    "dic = make_dict(Train)\n",
    "print(len(dic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = dic.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запись в файл count матрицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "for doc in Train:\n",
    "    new_title = conuntVec(doc, dic)\n",
    "    with open('countVecTrain.txt', 'a', encoding='utf-8') as out:\n",
    "        for i in list(new_title):\n",
    "            out.write('{},'.format(i))\n",
    "        out.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in Test:\n",
    "    new_title = conuntVec(doc, dic)\n",
    "    with open('countVecTest.txt', 'a', encoding='utf-8') as out:\n",
    "        for i in list(new_title):\n",
    "            out.write('{},'.format(i))\n",
    "        out.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтение файлов с матрицей tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = []\n",
    "with open('countVecTrain.txt', encoding='utf-8') as inp:\n",
    "    m = inp.readlines()\n",
    "    for i in m:\n",
    "        i = i[0:len(i)-2]\n",
    "        nn = list(map(float, i.split(',')))\n",
    "        Train.append(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = []\n",
    "with open('countVecTest.txt', encoding='utf-8') as inp:\n",
    "    m = inp.readlines()\n",
    "    for i in m:\n",
    "        i = i[0:len(i)-2]\n",
    "        nn = list(map(float, i.split(',')))\n",
    "        Test.append(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Test = pd.DataFrame(Test)\n",
    "Train = pd.DataFrame(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.read_csv('Y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train['Y'] = Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наивный Байесовский классификатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(Train):\n",
    "    dic = 3350\n",
    "    classes = range(1,11)\n",
    "    freq = []\n",
    "    clas = []\n",
    "    for i in classes:\n",
    "        feat =  np.zeros(dic)\n",
    "        kol = 0\n",
    "        l = Train[Train['Y']==i]\n",
    "        l.drop(['Y'], axis=1, inplace=True)\n",
    "        l = np.array(l)\n",
    "        for j in l:\n",
    "            summ = []\n",
    "            p = np.array(j)\n",
    "            for k in range(dic):\n",
    "                summ.append(p[k]+feat[k])\n",
    "            feat = summ\n",
    "            kol += 1\n",
    "        freq.append(feat)\n",
    "        clas.append(kol)\n",
    "    \n",
    "    \n",
    "    for i in range(len(freq)):\n",
    "        for j in range(len(freq[i])):\n",
    "            freq[i][j] = freq[i][j] / clas[i]\n",
    "    for c in range(len(clas)):              \n",
    "        clas[c] = clas[c] / len(Y)\n",
    "        \n",
    "    return clas, freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(clas, feats):\n",
    "    classes, prob = clas\n",
    "    pr = []\n",
    "    csl = []\n",
    "    for cl in range(len(classes)):\n",
    "        res = 0\n",
    "        for feat in range(len(feats)):\n",
    "            res += -log(prob[cl][feat]*feats[feat] + 10**(-7))\n",
    "        res += -log(classes[cl])\n",
    "        pr.append(res)\n",
    "        csl.append(cl)\n",
    "    return csl[pr.index(min(pr))]\n",
    "    return min(classes, key = lambda cl: -log(classes[cl]) + sum(-log(prob[cl]*feat, 10**(-7)) for feat in feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "classifier = train(Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pr = []\n",
    "for i in np.array(Test):\n",
    "    Y_pr.append(classify(classifier, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pr = pd.DataFrame(Y_pr)\n",
    "Y_pr.replace([0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
    "             ['business', 'culture', 'economics', 'forces', 'life', 'media', 'science', 'sport', 'style','travel'],\n",
    "             inplace=True)\n",
    "Y_pr.to_csv('Y_pr.csv', header=None, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
